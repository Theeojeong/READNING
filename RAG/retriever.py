"""
ê°ì • ê¸°ë°˜ ë¦¬íŠ¸ë¦¬ë²„ ëª¨ë“ˆ

ê³ ê¸‰ ê²€ìƒ‰ ì „ëµê³¼ ì»¨í…ìŠ¤íŠ¸ ì¬êµ¬ì„± ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from typing import List, Dict, Any, Optional, Callable
from utils.logger import log
from .vector_store import EmotionAwareVectorStore
from .emotion_chunker import EmotionChunk, create_overlapping_context


class EmotionAwareRetriever:
    """ê°ì • ì¸ì‹ ê²€ìƒ‰ ì—”ì§„"""

    def __init__(self, vector_store: EmotionAwareVectorStore):
        """
        ë¦¬íŠ¸ë¦¬ë²„ ì´ˆê¸°í™”

        Args:
            vector_store: EmotionAwareVectorStore ì¸ìŠ¤í„´ìŠ¤
        """
        self.vector_store = vector_store
        self.search_strategies = {
            "basic": self._basic_search,
            "emotion_boosted": self._emotion_boosted_search,
            "contextual": self._contextual_search,
            "hybrid": self._hybrid_search
        }

    def retrieve(
        self,
        query: str,
        k: int = 5,
        strategy: str = "emotion_boosted",
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        ê²€ìƒ‰ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ ì²­í¬ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜
            strategy: ê²€ìƒ‰ ì „ëµ ("basic", "emotion_boosted", "contextual", "hybrid")
            **kwargs: ì „ëµë³„ ì¶”ê°€ íŒŒë¼ë¯¸í„°

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if strategy not in self.search_strategies:
            log(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ì „ëµ: {strategy}, 'basic'ìœ¼ë¡œ í´ë°±")
            strategy = "basic"

        log(f"ğŸ” ê²€ìƒ‰ ì „ëµ: {strategy}")
        search_func = self.search_strategies[strategy]
        return search_func(query, k, **kwargs)

    def _basic_search(self, query: str, k: int, **kwargs) -> List[Dict[str, Any]]:
        """ê¸°ë³¸ ìœ ì‚¬ë„ ê²€ìƒ‰"""
        return self.vector_store.search(query, k=k)

    def _emotion_boosted_search(
        self,
        query: str,
        k: int,
        significance_boost: float = 0.1,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """ê°ì • ì „í™˜ì  ì¤‘ìš”ë„ë¥¼ ê³ ë ¤í•œ ê²€ìƒ‰"""
        return self.vector_store.search_with_emotion_boost(
            query,
            k=k,
            significance_boost=significance_boost
        )

    def _contextual_search(
        self,
        query: str,
        k: int,
        context_window: int = 1,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        ì•ë’¤ ë¬¸ë§¥ì„ í¬í•¨í•œ ê²€ìƒ‰

        Args:
            context_window: ì•ë’¤ë¡œ í¬í•¨í•  ì²­í¬ ê°œìˆ˜
        """
        # ê¸°ë³¸ ê²€ìƒ‰
        results = self.vector_store.search(query, k=k * 2)

        # ê° ê²°ê³¼ì— ë¬¸ë§¥ ì¶”ê°€
        contextual_results = []
        for result in results:
            chunk_id = result["metadata"].get("chunk_id", 0)
            document_id = result["metadata"].get("document_id", "default")

            # ì•ë’¤ ì²­í¬ ê°€ì ¸ì˜¤ê¸°
            context_chunks = []
            for offset in range(-context_window, context_window + 1):
                neighbor_id = f"{document_id}_chunk_{chunk_id + offset}"
                neighbor = self.vector_store.get_chunk_by_id(neighbor_id)
                if neighbor:
                    context_chunks.append(neighbor["document"])

            # ë¬¸ë§¥ ê²°í•©
            result["context"] = "\n\n".join(context_chunks) if context_chunks else result["document"]
            contextual_results.append(result)

        return contextual_results[:k]

    def _hybrid_search(
        self,
        query: str,
        k: int,
        emotion_weight: float = 0.3,
        context_window: int = 1,
        **kwargs
    ) -> List[Dict[str, Any]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰: ìœ ì‚¬ë„ + ê°ì • ì¤‘ìš”ë„ + ë¬¸ë§¥

        Args:
            emotion_weight: ê°ì • ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ (0-1)
            context_window: ë¬¸ë§¥ ìœˆë„ìš° í¬ê¸°
        """
        # 1. ê°ì • ë¶€ìŠ¤íŠ¸ ê²€ìƒ‰
        results = self.vector_store.search_with_emotion_boost(query, k=k * 3)

        # 2. ë¬¸ë§¥ ì¶”ê°€
        hybrid_results = []
        for result in results:
            chunk_id = result["metadata"].get("chunk_id", 0)
            document_id = result["metadata"].get("document_id", "default")

            # ë¬¸ë§¥ ê°€ì ¸ì˜¤ê¸°
            context_chunks = []
            for offset in range(-context_window, context_window + 1):
                neighbor_id = f"{document_id}_chunk_{chunk_id + offset}"
                neighbor = self.vector_store.get_chunk_by_id(neighbor_id)
                if neighbor:
                    context_chunks.append(neighbor["document"])

            result["context"] = "\n\n".join(context_chunks) if context_chunks else result["document"]

            # 3. ìµœì¢… ìŠ¤ì½”ì–´ ê³„ì‚°
            base_score = result.get("boosted_distance", result.get("distance", 0))
            significance = result["metadata"].get("transition_significance", 0)

            # í•˜ì´ë¸Œë¦¬ë“œ ìŠ¤ì½”ì–´ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
            hybrid_score = base_score * (1 - emotion_weight) + (5 - significance) * emotion_weight
            result["hybrid_score"] = hybrid_score

            hybrid_results.append(result)

        # ìµœì¢… ì •ë ¬
        hybrid_results.sort(key=lambda x: x["hybrid_score"])

        log(f"ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì™„ë£Œ: ìƒìœ„ {k}ê°œ ë°˜í™˜")
        return hybrid_results[:k]

    def retrieve_by_emotion(
        self,
        query: str,
        emotion: str,
        k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • ê°ì •ìœ¼ë¡œ í•„í„°ë§í•˜ì—¬ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            emotion: í•„í„°ë§í•  ê°ì • (ì˜ˆ: "ìŠ¬í””", "ê¸°ì¨")
            k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜

        Returns:
            ê°ì •ìœ¼ë¡œ í•„í„°ë§ëœ ê²€ìƒ‰ ê²°ê³¼
        """
        log(f"ğŸ˜Š ê°ì • í•„í„°: '{emotion}'")
        return self.vector_store.search(query, k=k, emotion_filter=emotion)

    def retrieve_transitions(
        self,
        query: str,
        min_significance: int = 3,
        k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        ì¤‘ìš”í•œ ê°ì • ì „í™˜ì ë§Œ ê²€ìƒ‰

        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            min_significance: ìµœì†Œ ì¤‘ìš”ë„ (1-5)
            k: ë°˜í™˜í•  ê²°ê³¼ ê°œìˆ˜

        Returns:
            ì¤‘ìš”í•œ ì „í™˜ì  ê²€ìƒ‰ ê²°ê³¼
        """
        log(f"ğŸ”„ ì „í™˜ì  ê²€ìƒ‰: ì¤‘ìš”ë„ >= {min_significance}")
        return self.vector_store.search(
            query,
            k=k,
            significance_threshold=min_significance
        )

    def format_results_for_llm(
        self,
        results: List[Dict[str, Any]],
        include_metadata: bool = True,
        use_context: bool = False
    ) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLMì— ì „ë‹¬í•˜ê¸° ì¢‹ì€ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            include_metadata: ë©”íƒ€ë°ì´í„° í¬í•¨ ì—¬ë¶€
            use_context: ë¬¸ë§¥ ì‚¬ìš© ì—¬ë¶€ (ìˆëŠ” ê²½ìš°)

        Returns:
            í¬ë§·íŒ…ëœ í…ìŠ¤íŠ¸
        """
        if not results:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        formatted_parts = []
        for i, result in enumerate(results, 1):
            text = result.get("context", result["document"]) if use_context else result["document"]

            part = f"[ê²°ê³¼ {i}]\n{text}"

            if include_metadata and result.get("metadata"):
                meta = result["metadata"]
                metadata_str = f"\n[ë©”íƒ€ë°ì´í„°: ê°ì •={meta.get('emotion', 'N/A')}"

                if meta.get("transition_significance"):
                    metadata_str += f", ì¤‘ìš”ë„={meta.get('transition_significance')}"

                if meta.get("next_emotion"):
                    metadata_str += f", ë‹¤ìŒê°ì •={meta.get('next_emotion')}"

                metadata_str += "]"
                part += metadata_str

            formatted_parts.append(part)

        return "\n\n---\n\n".join(formatted_parts)

    def get_emotional_arc(self, document_id: str = "default") -> List[Dict[str, Any]]:
        """
        ë¬¸ì„œì˜ ê°ì • ì•„í¬(íë¦„)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            document_id: ë¬¸ì„œ ID

        Returns:
            ê°ì • ì „í™˜ì  íƒ€ì„ë¼ì¸
        """
        # ëª¨ë“  ì²­í¬ë¥¼ ìœ„ì¹˜ ìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
        try:
            results = self.vector_store.collection.get(
                where={"document_id": document_id},
                limit=1000  # ì¶©ë¶„íˆ í° ìˆ˜
            )

            if not results["metadatas"]:
                return []

            # chunk_idë¡œ ì •ë ¬
            chunks_with_meta = [
                {
                    "chunk_id": meta.get("chunk_id", 0),
                    "emotion": meta.get("emotion", "unknown"),
                    "start_pos": meta.get("start_pos", 0),
                    "significance": meta.get("transition_significance"),
                    "next_emotion": meta.get("next_emotion"),
                    "explanation": meta.get("transition_explanation")
                }
                for meta in results["metadatas"]
            ]

            chunks_with_meta.sort(key=lambda x: x["chunk_id"])

            log(f"ğŸ“ˆ ê°ì • ì•„í¬ ì¶”ì¶œ: {len(chunks_with_meta)}ê°œ ì²­í¬")
            return chunks_with_meta

        except Exception as e:
            log(f"âŒ ê°ì • ì•„í¬ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def explain_results(self, results: List[Dict[str, Any]]) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ì— ëŒ€í•œ ì„¤ëª…ì„ ìƒì„±í•©ë‹ˆë‹¤.

        Args:
            results: ê²€ìƒ‰ ê²°ê³¼

        Returns:
            ì„¤ëª… í…ìŠ¤íŠ¸
        """
        if not results:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        explanation_parts = ["ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„:\n"]

        # ê°ì • ë¶„í¬
        emotions = [r["metadata"].get("emotion", "unknown") for r in results]
        emotion_counts = {}
        for emotion in emotions:
            emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

        explanation_parts.append(f"ê°ì • ë¶„í¬: {emotion_counts}")

        # ì „í™˜ì  ê°œìˆ˜
        transitions = sum(1 for r in results if r["metadata"].get("is_transition_point"))
        explanation_parts.append(f"ê°ì • ì „í™˜ì : {transitions}ê°œ")

        # í‰ê·  ì¤‘ìš”ë„
        significances = [
            r["metadata"].get("transition_significance", 0)
            for r in results
            if r["metadata"].get("transition_significance")
        ]
        if significances:
            avg_sig = sum(significances) / len(significances)
            explanation_parts.append(f"í‰ê·  ì¤‘ìš”ë„: {avg_sig:.2f}/5")

        return "\n".join(explanation_parts)
