"""
ê°ì • ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ì²­í‚¹ ëª¨ë“ˆ

í…ìŠ¤íŠ¸ë¥¼ ê°ì • ì „í™˜ì ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
"""

from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import re
from utils.logger import log
from services.analyze_emotions_with_gpt import analyze_emotions_with_gpt


@dataclass
class EmotionChunk:
    """ê°ì • ê¸°ë°˜ ì²­í¬ ë°ì´í„° í´ë˜ìŠ¤"""
    text: str
    emotion: str
    start_pos: int
    end_pos: int
    chunk_id: int
    metadata: Optional[Dict[str, Any]] = None

    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "text": self.text,
            "emotion": self.emotion,
            "start_pos": self.start_pos,
            "end_pos": self.end_pos,
            "chunk_id": self.chunk_id,
            "metadata": self.metadata or {}
        }


def split_text_by_emotions(
    text: str,
    max_chunk_size: int = 2000,
    min_chunk_size: int = 100,
    overlap_size: int = 50
) -> List[EmotionChunk]:
    """
    ê°ì • ì „í™˜ì ì„ ê¸°ì¤€ìœ¼ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²­í‚¹í•©ë‹ˆë‹¤.

    Args:
        text: ì „ì²´ í…ìŠ¤íŠ¸
        max_chunk_size: ì²­í¬ ìµœëŒ€ í¬ê¸° (ë¬¸ì ìˆ˜)
        min_chunk_size: ì²­í¬ ìµœì†Œ í¬ê¸° (ë¬¸ì ìˆ˜)
        overlap_size: ì²­í¬ ê°„ ì˜¤ë²„ë© í¬ê¸°

    Returns:
        EmotionChunk ê°ì²´ ë¦¬ìŠ¤íŠ¸
    """
    log(f"ğŸ“Š ê°ì • ê¸°ë°˜ ì²­í‚¹ ì‹œì‘: í…ìŠ¤íŠ¸ ê¸¸ì´ {len(text)}ì")

    # 1. ê°ì • ë¶„ì„ ì‹¤í–‰
    analysis_result = analyze_emotions_with_gpt(text)
    phases = analysis_result.get("emotional_phases", [])

    log(f"ğŸ” ê°ì • ì „í™˜ì  {len(phases)}ê°œ ë°œê²¬")

    if not phases:
        # ì „í™˜ì ì´ ì—†ìœ¼ë©´ ë¬¸ì¥ ë‹¨ìœ„ í´ë°±
        log("âš ï¸ ê°ì • ì „í™˜ì  ì—†ìŒ â†’ ë¬¸ì¥ ë‹¨ìœ„ ë¶„í• ë¡œ í´ë°±")
        return _fallback_sentence_split(text, max_chunk_size, overlap_size)

    # 2. ì „í™˜ì  ìœ„ì¹˜ë¡œ ì²­í¬ ê²½ê³„ ì„¤ì •
    chunks = []
    prev_position = 0
    chunk_id = 0

    for i, phase in enumerate(phases):
        position = phase.get("position_in_full_text")

        if position is None or position <= prev_position:
            log(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ ìœ„ì¹˜: {position} (ì´ì „: {prev_position})")
            continue

        # ë¬¸ì¥ ê²½ê³„ë¡œ ì¡°ì • (ë¬¸ì¥ ì¤‘ê°„ì—ì„œ ìë¥´ì§€ ì•Šê¸°)
        adjusted_position = _find_sentence_boundary(text, position)

        # ì´ì „ ìœ„ì¹˜ë¶€í„° í˜„ì¬ ì „í™˜ì ê¹Œì§€ë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ
        chunk_start = max(0, prev_position - overlap_size) if prev_position > 0 else 0
        chunk_text = text[chunk_start:adjusted_position].strip()

        if len(chunk_text) >= min_chunk_size:
            # ë„ˆë¬´ í¬ë©´ ë‹¤ì‹œ ë¶„í• 
            if len(chunk_text) > max_chunk_size:
                log(f"ğŸ“¦ í° ì²­í¬ ë¶„í• : {len(chunk_text)}ì â†’ {max_chunk_size}ì ë‹¨ìœ„")
                sub_chunks = _split_large_chunk(
                    chunk_text,
                    max_chunk_size,
                    phase.get("emotions_before", "neutral"),
                    chunk_start,
                    chunk_id
                )
                chunks.extend(sub_chunks)
                chunk_id += len(sub_chunks)
            else:
                chunk = EmotionChunk(
                    text=chunk_text,
                    emotion=phase.get("emotions_before", "neutral"),
                    start_pos=chunk_start,
                    end_pos=adjusted_position,
                    chunk_id=chunk_id,
                    metadata={
                        "next_emotion": phase.get("emotions_after"),
                        "transition_significance": phase.get("significance"),
                        "transition_explanation": phase.get("explanation"),
                        "is_transition_point": True
                    }
                )
                chunks.append(chunk)
                chunk_id += 1
                log(f"âœ… ì²­í¬ {chunk_id-1}: {len(chunk_text)}ì, ê°ì •: {chunk.emotion}")

        prev_position = adjusted_position

    # ë§ˆì§€ë§‰ ì²­í¬ ì²˜ë¦¬
    if prev_position < len(text):
        chunk_start = max(0, prev_position - overlap_size)
        last_chunk_text = text[chunk_start:].strip()

        if len(last_chunk_text) >= min_chunk_size:
            last_emotion = phases[-1].get("emotions_after", "neutral") if phases else "neutral"
            chunk = EmotionChunk(
                text=last_chunk_text,
                emotion=last_emotion,
                start_pos=chunk_start,
                end_pos=len(text),
                chunk_id=chunk_id,
                metadata={"is_last_chunk": True}
            )
            chunks.append(chunk)
            log(f"âœ… ë§ˆì§€ë§‰ ì²­í¬ {chunk_id}: {len(last_chunk_text)}ì")

    log(f"ğŸ‰ ì²­í‚¹ ì™„ë£Œ: ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„±")
    return chunks


def _find_sentence_boundary(text: str, position: int, search_range: int = 100) -> int:
    """
    ì£¼ì–´ì§„ ìœ„ì¹˜ ê·¼ì²˜ì—ì„œ ë¬¸ì¥ ê²½ê³„ë¥¼ ì°¾ìŠµë‹ˆë‹¤.

    Args:
        text: ì „ì²´ í…ìŠ¤íŠ¸
        position: ì‹œì‘ ìœ„ì¹˜
        search_range: ê²€ìƒ‰ ë²”ìœ„

    Returns:
        ì¡°ì •ëœ ìœ„ì¹˜ (ë¬¸ì¥ ë)
    """
    # ë¬¸ì¥ ì¢…ê²° ê¸°í˜¸
    sentence_endings = ['. ', '.\n', '! ', '!\n', '? ', '?\n', 'ã€‚', '! ', '? ', '\n\n']

    # position ê·¼ì²˜ì—ì„œ ë¬¸ì¥ ë ì°¾ê¸°
    search_start = max(0, position - search_range // 2)
    search_end = min(len(text), position + search_range // 2)
    search_text = text[search_start:search_end]

    # ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì¥ ë ì°¾ê¸°
    closest_end = -1
    closest_distance = float('inf')

    for ending in sentence_endings:
        idx = search_text.find(ending, max(0, position - search_start - 20))
        if idx != -1:
            actual_pos = search_start + idx + len(ending)
            distance = abs(actual_pos - position)
            if distance < closest_distance:
                closest_distance = distance
                closest_end = actual_pos

    return closest_end if closest_end != -1 else position


def _split_large_chunk(
    text: str,
    max_size: int,
    emotion: str,
    base_position: int,
    base_chunk_id: int
) -> List[EmotionChunk]:
    """
    í° ì²­í¬ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.

    Args:
        text: ë¶„í• í•  í…ìŠ¤íŠ¸
        max_size: ìµœëŒ€ í¬ê¸°
        emotion: í•´ë‹¹ ì²­í¬ì˜ ê°ì •
        base_position: ê¸°ì¤€ ìœ„ì¹˜
        base_chunk_id: ê¸°ì¤€ ì²­í¬ ID

    Returns:
        ë¶„í• ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    sentences = re.split(r'([.!?ã€‚!?]\s+|\n\n)', text)

    chunks = []
    current_chunk = ""
    current_start = 0
    chunk_count = 0

    for i in range(0, len(sentences), 2):
        sentence = sentences[i]
        separator = sentences[i + 1] if i + 1 < len(sentences) else ""
        full_sentence = sentence + separator

        if len(current_chunk) + len(full_sentence) > max_size and current_chunk:
            # í˜„ì¬ ì²­í¬ ì €ì¥
            chunk = EmotionChunk(
                text=current_chunk.strip(),
                emotion=emotion,
                start_pos=base_position + current_start,
                end_pos=base_position + current_start + len(current_chunk),
                chunk_id=base_chunk_id + chunk_count,
                metadata={"split_from_large_chunk": True}
            )
            chunks.append(chunk)

            current_start += len(current_chunk)
            current_chunk = full_sentence
            chunk_count += 1
        else:
            current_chunk += full_sentence

    # ë§ˆì§€ë§‰ ì²­í¬
    if current_chunk.strip():
        chunk = EmotionChunk(
            text=current_chunk.strip(),
            emotion=emotion,
            start_pos=base_position + current_start,
            end_pos=base_position + current_start + len(current_chunk),
            chunk_id=base_chunk_id + chunk_count,
            metadata={"split_from_large_chunk": True}
        )
        chunks.append(chunk)

    return chunks


def _fallback_sentence_split(
    text: str,
    max_size: int,
    overlap_size: int
) -> List[EmotionChunk]:
    """
    ê°ì • ë¶„ì„ ì‹¤íŒ¨ ì‹œ í´ë°±: ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• í•©ë‹ˆë‹¤.

    Args:
        text: ì „ì²´ í…ìŠ¤íŠ¸
        max_size: ìµœëŒ€ í¬ê¸°
        overlap_size: ì˜¤ë²„ë© í¬ê¸°

    Returns:
        ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
    sentences = re.split(r'([.!?ã€‚!?]\s+|\n\n)', text)

    chunks = []
    current_chunk = ""
    current_start = 0
    chunk_id = 0

    for i in range(0, len(sentences), 2):
        sentence = sentences[i]
        separator = sentences[i + 1] if i + 1 < len(sentences) else ""
        full_sentence = sentence + separator

        if len(current_chunk) + len(full_sentence) > max_size and current_chunk:
            # í˜„ì¬ ì²­í¬ ì €ì¥
            chunk = EmotionChunk(
                text=current_chunk.strip(),
                emotion="neutral",
                start_pos=current_start,
                end_pos=current_start + len(current_chunk),
                chunk_id=chunk_id,
                metadata={"fallback_split": True}
            )
            chunks.append(chunk)

            # ì˜¤ë²„ë© ì²˜ë¦¬
            overlap_text = current_chunk[-overlap_size:] if len(current_chunk) > overlap_size else ""
            current_start += len(current_chunk) - len(overlap_text)
            current_chunk = overlap_text + full_sentence
            chunk_id += 1
        else:
            current_chunk += full_sentence

    # ë§ˆì§€ë§‰ ì²­í¬
    if current_chunk.strip():
        chunk = EmotionChunk(
            text=current_chunk.strip(),
            emotion="neutral",
            start_pos=current_start,
            end_pos=len(text),
            chunk_id=chunk_id,
            metadata={"fallback_split": True}
        )
        chunks.append(chunk)

    log(f"ğŸ“¦ í´ë°± ë¶„í•  ì™„ë£Œ: {len(chunks)}ê°œ ì²­í¬")
    return chunks


def create_overlapping_context(
    chunks: List[EmotionChunk],
    target_chunk_id: int,
    context_window: int = 1
) -> str:
    """
    íŠ¹ì • ì²­í¬ì˜ ì•ë’¤ ë¬¸ë§¥ì„ í¬í•¨í•œ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        chunks: ì „ì²´ ì²­í¬ ë¦¬ìŠ¤íŠ¸
        target_chunk_id: ëŒ€ìƒ ì²­í¬ ID
        context_window: ì•ë’¤ë¡œ í¬í•¨í•  ì²­í¬ ê°œìˆ˜

    Returns:
        ë¬¸ë§¥ì´ í¬í•¨ëœ í…ìŠ¤íŠ¸
    """
    if not chunks or target_chunk_id >= len(chunks):
        return ""

    start_idx = max(0, target_chunk_id - context_window)
    end_idx = min(len(chunks), target_chunk_id + context_window + 1)

    context_chunks = chunks[start_idx:end_idx]
    return "\n\n".join([chunk.text for chunk in context_chunks])
