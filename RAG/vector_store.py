"""
Í∞êÏ†ï Í∏∞Î∞ò Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ Î™®Îìà

Ï≤≠ÌÅ¨Î•º ÏûÑÎ≤†Îî©ÌïòÍ≥† Î≤°ÌÑ∞ Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê Ï†ÄÏû•/Í≤ÄÏÉâÌï©ÎãàÎã§.
"""

from typing import List, Dict, Any, Optional, Tuple
import json
import os
from pathlib import Path
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from utils.logger import log
from .emotion_chunker import EmotionChunk


class EmotionAwareVectorStore:
    """Í∞êÏ†ï Î©îÌÉÄÎç∞Ïù¥ÌÑ∞Î•º Ìè¨Ìï®Ìïú Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥"""

    def __init__(
        self,
        collection_name: str = "emotion_chunks",
        persist_directory: str = "./chroma_db",
        embedding_model: str = "all-MiniLM-L6-v2"
    ):
        """
        Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ Ï¥àÍ∏∞Ìôî

        Args:
            collection_name: Ïª¨Î†âÏÖò Ïù¥Î¶Ñ
            persist_directory: Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨
            embedding_model: ÏûÑÎ≤†Îî© Î™®Îç∏ (sentence-transformers Î™®Îç∏Î™Ö)
        """
        self.collection_name = collection_name
        self.persist_directory = persist_directory

        # Chroma DB ÌÅ¥ÎùºÏù¥Ïñ∏Ìä∏ Ï¥àÍ∏∞Ìôî
        Path(persist_directory).mkdir(parents=True, exist_ok=True)

        self.client = chromadb.PersistentClient(
            path=persist_directory,
            settings=Settings(
                anonymized_telemetry=False,
                allow_reset=True
            )
        )

        # ÏûÑÎ≤†Îî© Ìï®Ïàò ÏÑ§Ï†ï
        self.embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name=embedding_model
        )

        # Ïª¨Î†âÏÖò ÏÉùÏÑ± ÎòêÎäî Í∞ÄÏ†∏Ïò§Í∏∞
        try:
            self.collection = self.client.get_collection(
                name=collection_name,
                embedding_function=self.embedding_function
            )
            log(f"üìö Í∏∞Ï°¥ Ïª¨Î†âÏÖò Î°úÎìú: {collection_name}")
        except:
            self.collection = self.client.create_collection(
                name=collection_name,
                embedding_function=self.embedding_function,
                metadata={"description": "Emotion-aware text chunks"}
            )
            log(f"‚ú® ÏÉà Ïª¨Î†âÏÖò ÏÉùÏÑ±: {collection_name}")

    def add_chunks(self, chunks: List[EmotionChunk], document_id: str = "default") -> None:
        """
        Ï≤≠ÌÅ¨Î•º Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥Ïóê Ï∂îÍ∞ÄÌï©ÎãàÎã§.

        Args:
            chunks: EmotionChunk Í∞ùÏ≤¥ Î¶¨Ïä§Ìä∏
            document_id: Î¨∏ÏÑú ÏãùÎ≥ÑÏûê
        """
        if not chunks:
            log("‚ö†Ô∏è Ï∂îÍ∞ÄÌï† Ï≤≠ÌÅ¨Í∞Ä ÏóÜÏäµÎãàÎã§")
            return

        log(f"üíæ Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥Ïóê {len(chunks)}Í∞ú Ï≤≠ÌÅ¨ Ï∂îÍ∞Ä Ï§ë...")

        # Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
        ids = []
        documents = []
        metadatas = []

        for chunk in chunks:
            chunk_full_id = f"{document_id}_chunk_{chunk.chunk_id}"
            ids.append(chunk_full_id)
            documents.append(chunk.text)

            # Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
            metadata = {
                "document_id": document_id,
                "chunk_id": chunk.chunk_id,
                "emotion": chunk.emotion,
                "start_pos": chunk.start_pos,
                "end_pos": chunk.end_pos,
                "text_length": len(chunk.text),
            }

            # Ï∂îÍ∞Ä Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Î≥ëÌï©
            if chunk.metadata:
                for key, value in chunk.metadata.items():
                    # ChromaÎäî Í∏∞Î≥∏ ÌÉÄÏûÖÎßå ÏßÄÏõêÌïòÎØÄÎ°ú Î≥ÄÌôò
                    if isinstance(value, (str, int, float, bool)):
                        metadata[key] = value
                    else:
                        metadata[key] = str(value)

            metadatas.append(metadata)

        # Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥Ïóê Ï∂îÍ∞Ä
        try:
            self.collection.add(
                ids=ids,
                documents=documents,
                metadatas=metadatas
            )
            log(f"‚úÖ {len(chunks)}Í∞ú Ï≤≠ÌÅ¨ Ï∂îÍ∞Ä ÏôÑÎ£å")
        except Exception as e:
            log(f"‚ùå Ï≤≠ÌÅ¨ Ï∂îÍ∞Ä Ïã§Ìå®: {e}")
            raise

    def search(
        self,
        query: str,
        k: int = 5,
        emotion_filter: Optional[str] = None,
        significance_threshold: Optional[int] = None
    ) -> List[Dict[str, Any]]:
        """
        Ïú†ÏÇ¨ÎèÑ Í≤ÄÏÉâÏùÑ ÏàòÌñâÌï©ÎãàÎã§.

        Args:
            query: Í≤ÄÏÉâ ÏøºÎ¶¨
            k: Î∞òÌôòÌï† Í≤∞Í≥º Í∞úÏàò
            emotion_filter: ÌäπÏ†ï Í∞êÏ†ïÏúºÎ°ú ÌïÑÌÑ∞ÎßÅ (Ïòà: "Ïä¨Ìîî")
            significance_threshold: ÏµúÏÜå Ï§ëÏöîÎèÑ (1-5)

        Returns:
            Í≤ÄÏÉâ Í≤∞Í≥º Î¶¨Ïä§Ìä∏ [{"document": str, "metadata": dict, "distance": float}]
        """
        log(f"üîç Í≤ÄÏÉâ ÏøºÎ¶¨: '{query[:50]}...' (k={k})")

        # ÌïÑÌÑ∞ Ï°∞Í±¥ ÏÉùÏÑ±
        where_filter = {}
        if emotion_filter:
            where_filter["emotion"] = emotion_filter
        if significance_threshold:
            where_filter["transition_significance"] = {"$gte": significance_threshold}

        try:
            # Í≤ÄÏÉâ Ïã§Ìñâ
            results = self.collection.query(
                query_texts=[query],
                n_results=k,
                where=where_filter if where_filter else None
            )

            # Í≤∞Í≥º Ìè¨Îß∑ÌåÖ
            formatted_results = []
            if results["documents"] and results["documents"][0]:
                for i, doc in enumerate(results["documents"][0]):
                    formatted_results.append({
                        "document": doc,
                        "metadata": results["metadatas"][0][i] if results["metadatas"] else {},
                        "distance": results["distances"][0][i] if results["distances"] else 0.0,
                        "id": results["ids"][0][i] if results["ids"] else ""
                    })

            log(f"‚úÖ Í≤ÄÏÉâ ÏôÑÎ£å: {len(formatted_results)}Í∞ú Í≤∞Í≥º")
            return formatted_results

        except Exception as e:
            log(f"‚ùå Í≤ÄÏÉâ Ïã§Ìå®: {e}")
            return []

    def search_with_emotion_boost(
        self,
        query: str,
        k: int = 5,
        significance_boost: float = 0.1
    ) -> List[Dict[str, Any]]:
        """
        Í∞êÏ†ï Ï†ÑÌôòÏ†ê Ï§ëÏöîÎèÑÎ•º Í≥†Î†§Ìïú Í≤ÄÏÉâ (Ïû¨Îû≠ÌÇπ)

        Args:
            query: Í≤ÄÏÉâ ÏøºÎ¶¨
            k: ÏµúÏ¢Ö Î∞òÌôòÌï† Í≤∞Í≥º Í∞úÏàò
            significance_boost: Ï§ëÏöîÎèÑÎãπ Î∂ÄÏä§Ìä∏ ÎπÑÏú® (Ïòà: 0.1 = 10%)

        Returns:
            Ïû¨Îû≠ÌÇπÎêú Í≤ÄÏÉâ Í≤∞Í≥º
        """
        # Îçî ÎßéÏù¥ Í≤ÄÏÉâ (Ïû¨Îû≠ÌÇπ ÏúÑÌï¥)
        results = self.search(query, k=k * 2)

        # Ï§ëÏöîÎèÑ Í∏∞Î∞ò Ïû¨Îû≠ÌÇπ
        for result in results:
            significance = result["metadata"].get("transition_significance", 0)
            original_distance = result["distance"]

            # Ï§ëÏöîÎèÑÍ∞Ä ÎÜíÏùÑÏàòÎ°ù Í±∞Î¶¨Î•º Ï§ÑÏûÑ (Ïú†ÏÇ¨ÎèÑ Ï¶ùÍ∞Ä)
            boosted_distance = original_distance * (1 - significance * significance_boost)
            result["original_distance"] = original_distance
            result["boosted_distance"] = boosted_distance

        # Ïû¨Ï†ïÎ†¨
        results.sort(key=lambda x: x["boosted_distance"])

        log(f"üéØ Ïû¨Îû≠ÌÇπ ÏôÑÎ£å: ÏÉÅÏúÑ {k}Í∞ú Î∞òÌôò")
        return results[:k]

    def get_chunk_by_id(self, chunk_id: str) -> Optional[Dict[str, Any]]:
        """
        IDÎ°ú Ï≤≠ÌÅ¨Î•º Í∞ÄÏ†∏ÏòµÎãàÎã§.

        Args:
            chunk_id: Ï≤≠ÌÅ¨ ID

        Returns:
            Ï≤≠ÌÅ¨ Îç∞Ïù¥ÌÑ∞ ÎòêÎäî None
        """
        try:
            result = self.collection.get(ids=[chunk_id])
            if result["documents"]:
                return {
                    "document": result["documents"][0],
                    "metadata": result["metadatas"][0] if result["metadatas"] else {},
                    "id": chunk_id
                }
        except Exception as e:
            log(f"‚ùå Ï≤≠ÌÅ¨ Ï°∞Ìöå Ïã§Ìå®: {e}")

        return None

    def delete_document(self, document_id: str) -> None:
        """
        ÌäπÏ†ï Î¨∏ÏÑúÏùò Î™®Îì† Ï≤≠ÌÅ¨Î•º ÏÇ≠Ï†úÌï©ÎãàÎã§.

        Args:
            document_id: Î¨∏ÏÑú ID
        """
        try:
            # document_idÎ°ú ÌïÑÌÑ∞ÎßÅÌïòÏó¨ ÏÇ≠Ï†ú
            self.collection.delete(where={"document_id": document_id})
            log(f"üóëÔ∏è Î¨∏ÏÑú ÏÇ≠Ï†ú ÏôÑÎ£å: {document_id}")
        except Exception as e:
            log(f"‚ùå Î¨∏ÏÑú ÏÇ≠Ï†ú Ïã§Ìå®: {e}")

    def clear_collection(self) -> None:
        """Ïª¨Î†âÏÖòÏùò Î™®Îì† Îç∞Ïù¥ÌÑ∞Î•º ÏÇ≠Ï†úÌï©ÎãàÎã§."""
        try:
            self.client.delete_collection(self.collection_name)
            self.collection = self.client.create_collection(
                name=self.collection_name,
                embedding_function=self.embedding_function
            )
            log(f"üóëÔ∏è Ïª¨Î†âÏÖò Ï¥àÍ∏∞Ìôî ÏôÑÎ£å: {self.collection_name}")
        except Exception as e:
            log(f"‚ùå Ïª¨Î†âÏÖò Ï¥àÍ∏∞Ìôî Ïã§Ìå®: {e}")

    def get_stats(self) -> Dict[str, Any]:
        """
        Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ ÌÜµÍ≥ÑÎ•º Î∞òÌôòÌï©ÎãàÎã§.

        Returns:
            ÌÜµÍ≥Ñ Ï†ïÎ≥¥ ÎîïÏÖîÎÑàÎ¶¨
        """
        try:
            count = self.collection.count()

            # Í∞êÏ†ïÎ≥Ñ Î∂ÑÌè¨ Í≥ÑÏÇ∞ (ÏÉòÌîåÎßÅ)
            sample_size = min(100, count)
            if sample_size > 0:
                sample = self.collection.get(limit=sample_size)
                emotions = [meta.get("emotion", "unknown") for meta in sample["metadatas"]]
                emotion_counts = {}
                for emotion in emotions:
                    emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

                return {
                    "total_chunks": count,
                    "collection_name": self.collection_name,
                    "emotion_distribution": emotion_counts,
                    "sample_size": sample_size
                }

            return {
                "total_chunks": count,
                "collection_name": self.collection_name
            }

        except Exception as e:
            log(f"‚ùå ÌÜµÍ≥Ñ Ï°∞Ìöå Ïã§Ìå®: {e}")
            return {"error": str(e)}
