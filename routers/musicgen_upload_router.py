import os
from typing import List, Dict, Any
from fastapi import (
    APIRouter,
    UploadFile,
    File,
    Form,
    HTTPException,
)
from services.model_manager import musicgen_manager
from services.mysql_service import mysql_service
from services import prompt_service
from services.async_emotion_analysis import process_book_with_async_emotion_detection
from services.async_music_generation import process_all_chunks_async
from services.workflow_refactored import music_workflow_refactored
from utils.file_utils import secure_filename
from utils.logger import log
from config import GEN_DURATION, OUTPUT_DIR, CHUNKS_PER_PAGE
import json
from services.text_processing_service import text_processing_service


router = APIRouter(prefix="/generate")


@router.post("/music")
async def generate_music_optimized(
    file: UploadFile = File(),
    user_name: str = Form(),
    book_title: str = Form()
):

    book_title = secure_filename(book_title)
    book_id = f"{user_name}_{book_title}"

    # ë””ë ‰í† ë¦¬ ì„¤ì •
    book_dir = f"{user_name}/{book_title}"
    abs_book_dir = os.path.join(OUTPUT_DIR, book_dir)
    if not os.path.exists(abs_book_dir):
        os.makedirs(abs_book_dir)

    # í…ìŠ¤íŠ¸ ì½ê¸°
    text = file.file.read().decode("utf-8")
    text_length = len(text)
    print(f"ğŸ“„ í…ìŠ¤íŠ¸ ê¸¸ì´: {text_length:,}ì")

    # ê¸€ë¡œë²Œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë°˜)
    global_prompt = prompt_service.generate_global(text)

    # ë¹„ë™ê¸° ê°ì • ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    log("ğŸ­ ë¹„ë™ê¸° ê°ì • ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    all_chunks = await process_book_with_async_emotion_detection(text)

    total_chunks = len(all_chunks)
    log(f"ğŸ­ ë¹„ë™ê¸° ê°ì • ë¶„ì„ ì™„ë£Œ: ì´ {total_chunks}ê°œ ì²­í¬ ìƒì„±")

    # í˜ì´ì§€ë³„ ì²­í¬ ë§¤í•‘ ìƒì„± (í•œ í˜ì´ì§€ë‹¹ ê³ ì • ì²­í¬ ìˆ˜)
    page_chunk_mapping = {}

    for i, chunk in enumerate[Dict[str, Any]](all_chunks):
        page_num = (i // CHUNKS_PER_PAGE) + 1
        if page_num not in page_chunk_mapping:
            page_chunk_mapping[page_num] = {
                "start_index": i + 1,
                "end_index": i + 1,
                "chunk_count": 0
            }
        page_chunk_mapping[page_num]["end_index"] = i + 1
        page_chunk_mapping[page_num]["chunk_count"] += 1
        chunk["page"] = page_num

    log(f"ğŸ“„ í˜ì´ì§€ êµ¬ì„±: ì´ {len(page_chunk_mapping)}í˜ì´ì§€, í˜ì´ì§€ë‹¹ {CHUNKS_PER_PAGE}ê°œ ì²­í¬")

    # ëª¨ë“  ì²­í¬ë¥¼ ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬
    print(f"ğŸµ {total_chunks}ê°œ ì²­í¬ ìŒì•… ìƒì„± ì‹œì‘...")
    chunk_metadata = await process_all_chunks_async(all_chunks, book_dir, global_prompt)

    # í˜ì´ì§€ë³„ë¡œ ì²­í¬ ê·¸ë£¹í™” ë° ì €ì¥
    page_results = []

    for page_num, mapping in page_chunk_mapping.items():
        start_idx = mapping["start_index"] - 1  # 0-based index
        end_idx = mapping["end_index"]

        # í•´ë‹¹ í˜ì´ì§€ì˜ ì²­í¬ë“¤ë§Œ ì¶”ì¶œ
        page_chunks = chunk_metadata[start_idx:end_idx]

        if not page_chunks:
            page_results.append({
                "page": page_num,
                "chunks": 0,
                "duration": 0,
                "error": "ì²­í¬ ìƒì„± ì‹¤íŒ¨"
            })
            continue

        # í˜ì´ì§€ë³„ ìŒì•… ê¸¸ì´ ê³„ì‚°
        page_duration = len(page_chunks) * GEN_DURATION

        # MySQLì— ì €ì¥
        try:
            mysql_service.save_chapter_chunks(
                book_id=book_id,
                page=page_num,
                chunks=page_chunks,
                total_duration=page_duration,
                book_title=book_title,
            )

            page_results.append({
                "page": page_num,
                "chunks": len(page_chunks),
                "duration": page_duration,
                "cached": False
            })

            print(f"âœ… í˜ì´ì§€ {page_num} ì €ì¥ ì™„ë£Œ: {len(page_chunks)}ê°œ ì²­í¬, {page_duration}ì´ˆ")

        except Exception as e:
            print(f"âŒ í˜ì´ì§€ {page_num} ì €ì¥ ì‹¤íŒ¨: {e}")
            page_results.append({
                "page": page_num,
                "error": str(e),
                "cached": False
            })

    # ì‘ë‹µ
    total_duration = sum(page.get("duration", 0) for page in page_results)
    successful_pages = len([p for p in page_results if "error" not in p])

    return {
        "message": f"{book_title} ìŒì•… ìƒì„± ì™„ë£Œ",
        "book_id": book_id,
        "text_length": text_length,
        "total_pages": len(page_chunk_mapping),
        "total_chunks": total_chunks,
        "total_duration": total_duration,
        "successful_pages": successful_pages,
        "pages": page_results,
    }



@router.post("/music-v3")
async def generate_music_v3(
    file: UploadFile = File(...),
    book_id: str = Form(...),
    user_name: str = Form(default="guest"),
    book_title: str = Form(default="untitled")
):
    """
    Music Generation V3
    - Supports PDF, EPUB, TXT
    """

    # If book_title is default but file has name, use filename
    if book_title == "untitled" and file.filename:
        book_title = os.path.splitext(file.filename)[0]
    
    book_title = secure_filename(book_title)
    # Use the provided book_id or construct one if needed. 
    # For consistency with file storage, we use user_name and book_title for directory.
    # But we pass the provided book_id to MySQL if that's what frontend expects.
    
    # Directory setup
    book_dir = f"{user_name}/{book_title}"
    abs_book_dir = os.path.join(OUTPUT_DIR, book_dir)
    if not os.path.exists(abs_book_dir):
        os.makedirs(abs_book_dir)

    # Text Extraction
    try:
        text = await text_processing_service.extract_text(file)
    except Exception as e:
        raise HTTPException(400, f"Text extraction failed: {str(e)}")

    text_length = len(text)
    print(f"ğŸ“„ Text Length: {text_length:,} chars")

    if text_length < 50:
        raise HTTPException(400, "Text is too short to generate music.")

    # Global Prompt (No Preferences)
    global_prompt = prompt_service.generate_global(text)

    # Async Emotion Analysis
    log("ğŸ­ Starting Async Emotion Analysis Workflow")
    all_chunks = await process_book_with_async_emotion_detection(text)
    total_chunks = len(all_chunks)
    log(f"ğŸ­ Emotion Analysis Complete: {total_chunks} chunks")

    # Page Mapping
    page_chunk_mapping = {}
    for i, chunk in enumerate(all_chunks):
        page_num = (i // CHUNKS_PER_PAGE) + 1
        if page_num not in page_chunk_mapping:
            page_chunk_mapping[page_num] = {
                "start_index": i + 1,
                "end_index": i + 1,
                "chunk_count": 0
            }
        page_chunk_mapping[page_num]["end_index"] = i + 1
        page_chunk_mapping[page_num]["chunk_count"] += 1
        chunk["page"] = page_num

    log(f"ğŸ“„ Page Config: {len(page_chunk_mapping)} pages, {CHUNKS_PER_PAGE} chunks/page")

    # Async Music Generation
    print(f"ğŸµ Generating music for {total_chunks} chunks...")
    chunk_metadata = await process_all_chunks_async(all_chunks, book_dir, global_prompt)

    # Save Results
    page_results = []

    for page_num, mapping in page_chunk_mapping.items():
        start_idx = mapping["start_index"] - 1
        end_idx = mapping["end_index"]
        page_chunks = chunk_metadata[start_idx:end_idx]

        if not page_chunks:
            page_results.append({
                "page": page_num,
                "chunks": 0,
                "duration": 0,
                "error": "Chunk generation failed"
            })
            continue

        page_duration = len(page_chunks) * GEN_DURATION

        try:
            mysql_service.save_chapter_chunks(
                book_id=book_id, # Use the ID from frontend
                page=page_num,
                chunks=page_chunks,
                total_duration=page_duration,
                book_title=book_title,
            )

            page_results.append({
                "page": page_num,
                "chunks": len(page_chunks),
                "duration": page_duration,
                "cached": False
            })
            print(f"âœ… Page {page_num} saved: {len(page_chunks)} chunks")

        except Exception as e:
            print(f"âŒ Page {page_num} save failed: {e}")
            page_results.append({
                "page": page_num,
                "error": str(e),
                "cached": False
            })

    total_duration = sum(page.get("duration", 0) for page in page_results)
    successful_pages = len([p for p in page_results if "error" not in p])

    return {
        "message": f"{book_title} Music Generation Complete",
        "book_id": book_id,
        "text_length": text_length,
        "total_pages": len(page_chunk_mapping),
        "total_chunks": total_chunks,
        "total_duration": total_duration,
        "successful_pages": successful_pages,
        "chapters": page_results, # Frontend expects "chapters"
    }

@router.post("/music-langgraph")
async def generate_music_with_langgraph(
    file: UploadFile = File(),
    user_name: str = Form(),
    book_title: str = Form()
):
    """
    ğŸš€ Refactored LangGraph-based music generation workflow.

    This endpoint uses Clean Architecture principles for:
    - Single Responsibility: Each component has ONE clear purpose
    - Dependency Injection: Services are testable and swappable
    - Type Safety: Strong typing throughout the pipeline
    - Error Handling: Functional error handling with Result types
    - Observability: Detailed performance metrics and logging

    Improvements over legacy /music endpoint:
    1. Emotion-based chunking - Splits at emotional transitions
    2. Significance filtering - Only processes important changes
    3. Automatic position calculation - No manual position tracking
    4. Batch processing - Concurrent emotion analysis
    5. Comprehensive metrics - Per-step timing and statistics

    Args:
        file: Text file to process (.txt format)
        user_name: User identifier for directory organization
        book_title: Title of the book/text

    Returns:
        WorkflowResult with:
        - Generated music files and metadata
        - Page-by-page breakdown
        - Performance metrics
        - Error details (if any)

    Raises:
        HTTPException: On validation or processing failures
    """
    # Input validation
    book_title = secure_filename(book_title)
    book_id = f"{user_name}_{book_title}"

    # Setup output directory
    book_dir = f"{user_name}/{book_title}"
    abs_book_dir = os.path.join(OUTPUT_DIR, book_dir)
    if not os.path.exists(abs_book_dir):
        os.makedirs(abs_book_dir)

    # Read and validate text
    text = file.file.read().decode("utf-8")
    text_length = len(text)

    if text_length < 100:
        raise HTTPException(
            status_code=400,
            detail="Text too short. Minimum 100 characters required."
        )

    log(f"ğŸ“„ Processing: {book_title} ({text_length:,} chars)")

    # Execute refactored workflow
    result = await music_workflow_refactored.run_workflow(
        text=text,
        user_name=user_name,
        book_title=book_title,
        book_id=book_id,
        book_dir=book_dir
    )

    # Check for errors
    if result.get("errors"):
        log(f"âš ï¸ Workflow completed with errors: {result['errors']}")

    # Return comprehensive result
    return result



@router.get("/health")
async def health_check():

    health_status = {
        "status": "healthy",
        "timestamp": str(__import__("datetime").datetime.now()),
        "checks": {},
    }

    # MySQL ì—°ê²° ì²´í¬
    try:
        mysql_healthy = mysql_service.health_check()
        health_status["checks"]["mysql"] = {
            "status": "ok" if mysql_healthy else "error",
            "message": "MySQL ì—°ê²° ì •ìƒ" if mysql_healthy else "MySQL ì—°ê²° ì‹¤íŒ¨",
        }
    except Exception as e:
        health_status["checks"]["mysql"] = {
            "status": "error",
            "message": f"MySQL ì²´í¬ ì‹¤íŒ¨: {str(e)}",
        }
        health_status["status"] = "unhealthy"

    # MusicGen ëª¨ë¸ ì²´í¬
    try:
        model_loaded = musicgen_manager.model is not None
        health_status["checks"]["musicgen"] = {
            "status": "ok" if model_loaded else "not_loaded",
            "message": (
                "MusicGen ëª¨ë¸ ë¡œë“œë¨"
                if model_loaded
                else "ëª¨ë¸ ë¯¸ë¡œë“œ (ì²« ìš”ì²­ ì‹œ ë¡œë“œë¨)"
            ),
        }
    except Exception as e:
        health_status["checks"]["musicgen"] = {
            "status": "error",
            "message": f"ëª¨ë¸ ì²´í¬ ì‹¤íŒ¨: {str(e)}",
        }

    # 4) ì¶œë ¥ ë””ë ‰í† ë¦¬ ì²´í¬
    try:
        output_exists = os.path.exists(OUTPUT_DIR)
        health_status["checks"]["output_dir"] = {
            "status": "ok" if output_exists else "error",
            "path": OUTPUT_DIR,
            "message": "ì¶œë ¥ ë””ë ‰í† ë¦¬ ì •ìƒ" if output_exists else "ì¶œë ¥ ë””ë ‰í† ë¦¬ ì—†ìŒ",
        }

        if not output_exists:
            health_status["status"] = "unhealthy"
    except Exception as e:
        health_status["checks"]["output_dir"] = {
            "status": "error",
            "message": f"ë””ë ‰í† ë¦¬ ì²´í¬ ì‹¤íŒ¨: {str(e)}",
        }

    # ì „ì²´ ìƒíƒœ ì½”ë“œ ê²°ì •
    if health_status["status"] == "unhealthy":
        raise HTTPException(503, detail=health_status)

    return health_status


@router.post("/music-by-chapter")
async def get_music_by_chapter(
    book_id: str = Form(...),
    chapter_index: str = Form(...),
    chapter_title: str = Form(default=""),
    text: str = Form(default="")
):
    """
    ì±•í„°ë³„ ìŒì•… ë°ì´í„° ì¡°íšŒ (EpubViewerìš©)
    ì´ë¯¸ ìƒì„±ëœ ë°ì´í„°ë¥¼ MySQLì—ì„œ ì¡°íšŒí•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        # EpubViewerëŠ” 0-based indexë¥¼ ì‚¬ìš©í•˜ì§€ë§Œ, DBëŠ” 1-based pageë¥¼ ì‚¬ìš©
        page = int(chapter_index) + 1
        
        log(f"ğŸµ ì±•í„° ìŒì•… ì¡°íšŒ ìš”ì²­: book_id={book_id}, page={page}")
        
        result = mysql_service.get_chapter_chunks(book_id, page)
        
        if result:
            return result
        else:
            # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜ (ë˜ëŠ” ì—¬ê¸°ì„œ ì‹¤ì‹œê°„ ìƒì„± ë¡œì§ ì¶”ê°€ ê°€ëŠ¥)
            log(f"âš ï¸ ì±•í„° ë°ì´í„° ì—†ìŒ: {book_id}, page {page}")
            return {"chunks": []}
            
    except Exception as e:
        log(f"âŒ ì±•í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(500, str(e))
