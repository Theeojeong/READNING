import os
from typing import List, Dict, Any
from fastapi import (
    APIRouter,
    UploadFile,
    File,
    Form,
    HTTPException,
)
from services.model_manager import musicgen_manager
from services.mysql_service import mysql_service
from services import prompt_service
from services.async_emotion_analysis import process_book_with_async_emotion_detection
from services.async_music_generation import process_all_chunks_async
from services.langgraph_workflow import music_workflow
from utils.file_utils import secure_filename
from utils.logger import log
from config import GEN_DURATION, OUTPUT_DIR


router = APIRouter(prefix="/generate")


@router.post("/music")
async def generate_music_optimized(
    file: UploadFile = File(), 
    user_name: str = Form(), 
    book_title: str = Form()
):

    book_title = secure_filename(book_title)
    book_id = f"{user_name}_{book_title}"
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    book_dir = f"{user_name}/{book_title}"
    abs_bookdir = os.path.join(OUTPUT_DIR, book_dir)
    
    if not os.path.exists(abs_bookdir):
        os.makedirs(abs_bookdir)
    
    # í…ìŠ¤íŠ¸ ì½ê¸°
    text = file.file.read().decode("utf-8")
    text_length = len(text)
    print(f"ğŸ“„ í…ìŠ¤íŠ¸ ê¸¸ì´: {text_length:,}ì")
    
    # ê¸€ë¡œë²Œ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì „ì²´ í…ìŠ¤íŠ¸ ê¸°ë°˜)
    global_prompt = prompt_service.generate_global(text)
    
    # ë¹„ë™ê¸° ê°ì • ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    log("ğŸ­ ë¹„ë™ê¸° ê°ì • ë¶„ì„ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
    all_chunks = await process_book_with_async_emotion_detection(text)
    
    total_chunks = len(all_chunks)
    log(f"ğŸ­ ë¹„ë™ê¸° ê°ì • ë¶„ì„ ì™„ë£Œ: ì´ {total_chunks}ê°œ ì²­í¬ ìƒì„±")
    
    # í˜ì´ì§€ë³„ ì²­í¬ ë§¤í•‘ ìƒì„± (í•œ í˜ì´ì§€ë‹¹ 4ê°œ ì²­í¬ ê³ ì •)
    page_chunk_mapping = {}
    CHUNKS_PER_PAGE = 4  # í•œ í˜ì´ì§€ë‹¹ ì²­í¬ ìˆ˜ ê³ ì •
    
    for i, chunk in enumerate(all_chunks):
        page_num = (i // CHUNKS_PER_PAGE) + 1
        if page_num not in page_chunk_mapping:
            page_chunk_mapping[page_num] = {
                "start_index": i + 1,
                "end_index": i + 1,
                "chunk_count": 0
            }
        page_chunk_mapping[page_num]["end_index"] = i + 1
        page_chunk_mapping[page_num]["chunk_count"] += 1
        chunk["page"] = page_num
    
    log(f"ğŸ“„ í˜ì´ì§€ êµ¬ì„±: ì´ {len(page_chunk_mapping)}í˜ì´ì§€, í˜ì´ì§€ë‹¹ {CHUNKS_PER_PAGE}ê°œ ì²­í¬")
    
    # ëª¨ë“  ì²­í¬ë¥¼ ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬
    print(f"ğŸµ {total_chunks}ê°œ ì²­í¬ ìŒì•… ìƒì„± ì‹œì‘...")
    chunk_metadata = await process_all_chunks_async(all_chunks, book_dir, global_prompt)
    
    # í˜ì´ì§€ë³„ë¡œ ì²­í¬ ê·¸ë£¹í™” ë° ì €ì¥
    page_results = []
    
    for page_num, mapping in page_chunk_mapping.items():
        start_idx = mapping["start_index"] - 1  # 0-based index
        end_idx = mapping["end_index"]
        
        # í•´ë‹¹ í˜ì´ì§€ì˜ ì²­í¬ë“¤ë§Œ ì¶”ì¶œ
        page_chunks = chunk_metadata[start_idx:end_idx]
        
        if not page_chunks:
            page_results.append({
                "page": page_num,
                "chunks": 0,
                "duration": 0,
                "error": "ì²­í¬ ìƒì„± ì‹¤íŒ¨"
            })
            continue
        
        # í˜ì´ì§€ë³„ ìŒì•… ê¸¸ì´ ê³„ì‚°
        page_duration = len(page_chunks) * GEN_DURATION
        
        # MySQLì— ì €ì¥
        try:
            mysql_service.save_chapter_chunks(
                book_id=book_id,
                page=page_num,
                chunks=page_chunks,
                total_duration=page_duration,
                book_title=book_title,
            )
            
            page_results.append({
                "page": page_num,
                "chunks": len(page_chunks),
                "duration": page_duration,
                "cached": False
            })
            
            print(f"âœ… í˜ì´ì§€ {page_num} ì €ì¥ ì™„ë£Œ: {len(page_chunks)}ê°œ ì²­í¬, {page_duration}ì´ˆ")
            
        except Exception as e:
            print(f"âŒ í˜ì´ì§€ {page_num} ì €ì¥ ì‹¤íŒ¨: {e}")
            page_results.append({
                "page": page_num,
                "error": str(e),
                "cached": False
            })
    
    # ì‘ë‹µ
    total_duration = sum(page.get("duration", 0) for page in page_results)
    successful_pages = len([p for p in page_results if "error" not in p])
    
    return {
        "message": f"{book_title} ìŒì•… ìƒì„± ì™„ë£Œ",
        "book_id": book_id,
        "text_length": text_length,
        "total_pages": len(page_chunk_mapping),
        "total_chunks": total_chunks,
        "total_duration": total_duration,
        "successful_pages": successful_pages,
        "pages": page_results,
        "processing_method": "async_emotion_detection_parallel",
        "performance_optimizations": {
            "max_concurrent_emotion_analysis": 8,
            "max_concurrent_music_generation": 4,
            "emotion_analysis_timeout": 45.0
        }
    }



@router.post("/music-langgraph")
async def generate_music_with_langgraph(
    file: UploadFile = File(), 
    user_name: str = Form(), 
    book_title: str = Form()
):
    """
    ğŸš€ LangGraph ê¸°ë°˜ ìŒì•… ìƒì„± ì›Œí¬í”Œë¡œìš°:
    1. í…ìŠ¤íŠ¸ ë¶„ë¦¬ â†’ 2. ê°ì • ë¶„ì„ â†’ 3. ì²­í¬ ìƒì„± â†’ 4. ìŒì•… ìƒì„± â†’ 5. DB ì €ì¥
    ëª¨ë“  ë‹¨ê³„ê°€ ê·¸ë˜í”„ë¡œ ê´€ë¦¬ë˜ì–´ ì‹œê°í™” ë° ë””ë²„ê¹…ì´ ìš©ì´í•¨
    """
    
    book_title = secure_filename(book_title)
    book_id = f"{user_name}_{book_title}"
    
    # ë””ë ‰í† ë¦¬ ì„¤ì •
    book_dir = f"{user_name}/{book_title}"
    abs_bookdir = os.path.join(OUTPUT_DIR, book_dir)
    
    if not os.path.exists(abs_bookdir):
        os.makedirs(abs_bookdir)
    
    # í…ìŠ¤íŠ¸ ì½ê¸°
    text = file.file.read().decode("utf-8")
    text_length = len(text)
    log(f"ğŸ“„ LangGraph: í…ìŠ¤íŠ¸ ê¸¸ì´ {text_length:,}ì")
    
    # LangGraph ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    result = await music_workflow.run_workflow(
        text=text,
        user_name=user_name,
        book_title=book_title,
        book_id=book_id,
        book_dir=book_dir
    )
    
    return result







@router.get("/health")
async def health_check():

    health_status = {
        "status": "healthy",
        "timestamp": str(__import__("datetime").datetime.now()),
        "checks": {},
    }

    # MySQL ì—°ê²° ì²´í¬
    try:
        mysql_healthy = mysql_service.health_check()
        health_status["checks"]["mysql"] = {
            "status": "ok" if mysql_healthy else "error",
            "message": "MySQL ì—°ê²° ì •ìƒ" if mysql_healthy else "MySQL ì—°ê²° ì‹¤íŒ¨",
        }
    except Exception as e:
        health_status["checks"]["mysql"] = {
            "status": "error",
            "message": f"MySQL ì²´í¬ ì‹¤íŒ¨: {str(e)}",
        }
        health_status["status"] = "unhealthy"

    # MusicGen ëª¨ë¸ ì²´í¬
    try:
        model_loaded = musicgen_manager.model is not None
        health_status["checks"]["musicgen"] = {
            "status": "ok" if model_loaded else "not_loaded",
            "message": (
                "MusicGen ëª¨ë¸ ë¡œë“œë¨"
                if model_loaded
                else "ëª¨ë¸ ë¯¸ë¡œë“œ (ì²« ìš”ì²­ ì‹œ ë¡œë“œë¨)"
            ),
        }
    except Exception as e:
        health_status["checks"]["musicgen"] = {
            "status": "error",
            "message": f"ëª¨ë¸ ì²´í¬ ì‹¤íŒ¨: {str(e)}",
        }

    # 4) ì¶œë ¥ ë””ë ‰í† ë¦¬ ì²´í¬
    try:
        output_exists = os.path.exists(OUTPUT_DIR)
        health_status["checks"]["output_dir"] = {
            "status": "ok" if output_exists else "error",
            "path": OUTPUT_DIR,
            "message": "ì¶œë ¥ ë””ë ‰í† ë¦¬ ì •ìƒ" if output_exists else "ì¶œë ¥ ë””ë ‰í† ë¦¬ ì—†ìŒ",
        }

        if not output_exists:
            health_status["status"] = "unhealthy"
    except Exception as e:
        health_status["checks"]["output_dir"] = {
            "status": "error",
            "message": f"ë””ë ‰í† ë¦¬ ì²´í¬ ì‹¤íŒ¨: {str(e)}",
        }

    # ì „ì²´ ìƒíƒœ ì½”ë“œ ê²°ì •
    if health_status["status"] == "unhealthy":
        raise HTTPException(503, detail=health_status)

    return health_status
