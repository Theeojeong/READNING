import nltk, os
from pprint import pprint
from config import MAX_SEGMENT_SIZE, OVERLAP_SIZE
from typing import Generator, Tuple, List
from nltk.tokenize import sent_tokenize
from utils.logger import log

NLTK_DIR = os.path.join(os.path.dirname(__file__), "..", "nltk_data")
nltk.data.path.append(NLTK_DIR)      # í”„ë¡œì íŠ¸ ì•ˆ ìºì‹œ ê²½ë¡œ ì¶”ê°€

def ensure_punkt() -> None:
    """punkt í† í¬ë‚˜ì´ì €ê°€ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œí•œë‹¤(ìµœì´ˆ 1íšŒ)."""
    try:
        nltk.data.find("tokenizers/punkt")
        print("NLTK 'punkt' í™•ì¸ ì™„ë£Œ.")
    except LookupError:
        print("NLTK 'punkt' ë‹¤ìš´ë¡œë“œ ì¤‘...")
        nltk.download("punkt", download_dir=NLTK_DIR, quiet=True)
        print("NLTK 'punkt' ë‹¤ìš´ë¡œë“œ ì™„ë£Œ.")

ensure_punkt()

# ë¬¸ì¥ ê²½ê³„ íƒìƒ‰ ê´€ë ¨ ìƒìˆ˜
SENTENCE_SEARCH_RATIO = 0.8  # ë§ˆì§€ë§‰ 20% êµ¬ê°„ë§Œ ê²€ì‚¬
LOOKAHEAD_CHARS = 200        # ë¬¸ì¥ ëì„ ì°¾ê¸° ìœ„í•œ ì—¬ìœ  ë¬¸ì ìˆ˜


def _find_sentence_boundary(
    text: str,
    start_pos: int,
    initial_end_pos: int,
    max_end_pos: int
) -> int:
    # ê²€ìƒ‰ êµ¬ê°„ ì„¤ì •: ë§ˆì§€ë§‰ 20% êµ¬ê°„ë§Œ ê²€ì‚¬ (ì„±ëŠ¥ ìµœì í™”)
    search_start = max(
        start_pos + int(MAX_SEGMENT_SIZE * SENTENCE_SEARCH_RATIO),
        start_pos
    )
    search_end = min(initial_end_pos + LOOKAHEAD_CHARS, max_end_pos)
    search_text = text[search_start:search_end]
    
    try:
        sentences = sent_tokenize(search_text)
        if not sentences:
            return initial_end_pos
        
        # ë’¤ì—ì„œë¶€í„° ì™„ì „í•œ ë¬¸ì¥ ë ì°¾ê¸°
        for sentence in reversed(sentences):
            sentence_pos = search_text.rfind(sentence)
            if sentence_pos == -1:
                continue
            
            # ì ˆëŒ€ ìœ„ì¹˜ ê³„ì‚°
            absolute_end = search_start + sentence_pos + len(sentence)
            
            # ìœ íš¨ ë²”ìœ„ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
            if start_pos < absolute_end <= start_pos + MAX_SEGMENT_SIZE:
                return absolute_end
        
        return initial_end_pos
        
    except Exception as e:
        log(f"ë¬¸ì¥ í† í°í™” ì˜¤ë¥˜(ë¬´ì‹œ): {e}")
        return initial_end_pos


def split_text_into_processing_segments(text: str) -> Generator[Tuple[str, int], None, None]:
    """
    í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„í•  (ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì ìš©)
    """
    total_length = len(text)
    
    # 1ë‹¨ê³„: ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ë¶„í•  ë¶ˆí•„ìš”
    if total_length <= MAX_SEGMENT_SIZE:
        yield text, 0
        return
    
    # 2ë‹¨ê³„: í…ìŠ¤íŠ¸ë¥¼ ìˆœíšŒí•˜ë©° ì²­í¬ ìƒì„±
    current_pos = 0
    
    while current_pos < total_length:
        # ìµœëŒ€ í¬ê¸°ë§Œí¼ ìë¥´ê¸°
        chunk_end = min(current_pos + MAX_SEGMENT_SIZE, total_length)
        
        # í…ìŠ¤íŠ¸ê°€ ë” ë‚¨ì•„ìˆë‹¤ë©´ ë¬¸ì¥ ê²½ê³„ë¡œ ì¡°ì •
        is_text_remaining = chunk_end < total_length
        if is_text_remaining:
            chunk_end = _find_sentence_boundary(
                text=text,
                start_pos=current_pos,
                initial_end_pos=chunk_end,
                max_end_pos=total_length
            )
        
        # ì²­í¬ ë°˜í™˜
        chunk_text = text[current_pos:chunk_end]
        yield chunk_text, current_pos
        
        # ë§ˆì§€ë§‰ ì²­í¬ë©´ ì¢…ë£Œ
        if chunk_end == total_length:
            break
        
        # ë‹¤ìŒ ì²­í¬ ì‹œì‘ ìœ„ì¹˜ (ë§¥ë½ ìœ ì§€ë¥¼ ìœ„í•´ ì¼ë¶€ ê²¹ì¹¨)
        next_pos = chunk_end - OVERLAP_SIZE
        current_pos = max(current_pos + 1, next_pos)
    
    log("í…ìŠ¤íŠ¸ ë¶„í•  ì™„ë£Œ")


def split_text_with_sliding_window(text: str, max_size: int = 6000, overlap: int = 600) -> List[str]:
    """
    ğŸš€ ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë°©ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„í• 
    í˜ì´ì§€ ê²½ê³„ì—ì„œ ì¤‘ìš”í•œ ê°ì • ì „í™˜ì ì„ ë†“ì¹˜ì§€ ì•ŠìŒ
    
    Args:
        text: ë¶„í• í•  í…ìŠ¤íŠ¸
        max_size: ìµœëŒ€ í˜ì´ì§€ í¬ê¸° (ê¸°ë³¸ 6000ì)
        overlap: ì˜¤ë²„ë© í¬ê¸° (ê¸°ë³¸ 600ì)
    
    Returns:
        ë¶„í• ëœ í˜ì´ì§€ ë¦¬ìŠ¤íŠ¸
    """
    if len(text) <= max_size:
        return [text]
    
    pages = []
    pos = 0
    
    while pos < len(text):
        # ê¸°ë³¸ í˜ì´ì§€ í¬ê¸°
        end = min(pos + max_size, len(text))
        
        if end < len(text):
            # ë‹¤ìŒ í˜ì´ì§€ ì‹œì‘ ë¶€ë¶„ ë¯¸ë¦¬ë³´ê¸° (ì˜¤ë²„ë©)
            page_text = text[pos:end + overlap]
        else:
            # ë§ˆì§€ë§‰ í˜ì´ì§€
            page_text = text[pos:end]
        
        pages.append(page_text)
        pos = end  # ì˜¤ë²„ë© ì œì™¸í•˜ê³  ë‹¤ìŒ ì‹œì‘ì ìœ¼ë¡œ ì´ë™
    
    print(f"ğŸ“– ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ë¶„í• : {len(pages)}ê°œ í˜ì´ì§€ (ì˜¤ë²„ë©: {overlap}ì)")
    return pages